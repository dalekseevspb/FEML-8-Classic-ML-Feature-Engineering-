{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b209837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Алексеев Д.П. (DSU-4,FEML-8)\n",
    "# Домашнее задание к лекции «Улучшение качества модели» (#12).\n",
    "\n",
    "# Задание:\n",
    "# Взять boston house-prices dataset (sklearn.datasets.load_boston) и сделать то же самое для задачи регрессии \n",
    "# (попробовать разные алгоритмы, поподбирать параметры, вывести итоговое качество)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8944190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e249680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f245875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5fcaa",
   "metadata": {},
   "source": [
    "Для начала попробуем разбивку в цикле на трейн/тест и обучение модели регрессора методом KNN.\n",
    "Затем посчитаем усредненный коэфф-т детерминации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1779b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99538fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация:  1 Коэфф.детерминации:  0.4668670321887842\n",
      "Итерация:  2 Коэфф.детерминации:  0.49967475789335647\n",
      "Итерация:  3 Коэфф.детерминации:  0.40238087228330155\n",
      "Итерация:  4 Коэфф.детерминации:  0.40958651571520754\n",
      "Итерация:  5 Коэфф.детерминации:  0.6151441288370529\n",
      "Итерация:  6 Коэфф.детерминации:  0.5092360872500814\n",
      "Итерация:  7 Коэфф.детерминации:  0.6011647874151518\n",
      "Итерация:  8 Коэфф.детерминации:  0.6328605098343749\n",
      "Итерация:  9 Коэфф.детерминации:  0.5642588230919596\n",
      "Итерация:  10 Коэфф.детерминации:  0.5781056831344216\n",
      "Итерация:  11 Коэфф.детерминации:  0.5217950814675971\n",
      "Итерация:  12 Коэфф.детерминации:  0.5465634389888302\n",
      "Итерация:  13 Коэфф.детерминации:  0.4257703107798406\n",
      "Итерация:  14 Коэфф.детерминации:  0.5788265825251127\n",
      "Итерация:  15 Коэфф.детерминации:  0.5013307183533983\n",
      "Итерация:  16 Коэфф.детерминации:  0.5006414536648102\n",
      "Итерация:  17 Коэфф.детерминации:  0.6625460928644236\n",
      "Итерация:  18 Коэфф.детерминации:  0.5332300395974534\n",
      "Итерация:  19 Коэфф.детерминации:  0.6252025151270798\n",
      "Итерация:  20 Коэфф.детерминации:  0.4974770795408\n",
      "Усредненный коэфф-т детерминации: 0.533633125527652\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for i in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = KNeighborsRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "    score += model.score(X_test, y_test)\n",
    "    print(\"Итерация: \", i+1, \"Коэфф.детерминации: \", model.score(X_test, y_test))\n",
    "    \n",
    "print(\"Усредненный коэфф-т детерминации:\", score/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c055e351",
   "metadata": {},
   "source": [
    "Мы видим, что усредненный коэфф-т детерминации с использованием KNeighborsRegressor недостаточен для того, \n",
    "чтобы считать модель хорошей - не превышает 53% (хотя при некоторых вариантах разбивки на трейн/тест доходил до 66%).\n",
    "\n",
    "Попробуем то же самое на модели линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ce0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94295671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация:  1 Коэфф.детерминации:  0.794273611911878\n",
      "Итерация:  2 Коэфф.детерминации:  0.7179157791131988\n",
      "Итерация:  3 Коэфф.детерминации:  0.7158459558464332\n",
      "Итерация:  4 Коэфф.детерминации:  0.7292862387511923\n",
      "Итерация:  5 Коэфф.детерминации:  0.8085685263069367\n",
      "Итерация:  6 Коэфф.детерминации:  0.730513244895076\n",
      "Итерация:  7 Коэфф.детерминации:  0.7310830957992407\n",
      "Итерация:  8 Коэфф.детерминации:  0.7659362883368847\n",
      "Итерация:  9 Коэфф.детерминации:  0.7424819742306208\n",
      "Итерация:  10 Коэфф.детерминации:  0.7048949318879716\n",
      "Итерация:  11 Коэфф.детерминации:  0.6969104500099276\n",
      "Итерация:  12 Коэфф.детерминации:  0.7320744497815714\n",
      "Итерация:  13 Коэфф.детерминации:  0.750105270133656\n",
      "Итерация:  14 Коэфф.детерминации:  0.7438477064092606\n",
      "Итерация:  15 Коэфф.детерминации:  0.69113741020492\n",
      "Итерация:  16 Коэфф.детерминации:  0.7032972122768713\n",
      "Итерация:  17 Коэфф.детерминации:  0.6837983817374502\n",
      "Итерация:  18 Коэфф.детерминации:  0.803471071416304\n",
      "Итерация:  19 Коэфф.детерминации:  0.6953582930535691\n",
      "Итерация:  20 Коэфф.детерминации:  0.7418170157478672\n",
      "Усредненный коэфф-т детерминации: 0.7341308453925415\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "\n",
    "for i in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    score += model.score(X_test, y_test)\n",
    "    print(\"Итерация: \", i+1, \"Коэфф.детерминации: \", model.score(X_test, y_test))\n",
    "    \n",
    "print(\"Усредненный коэфф-т детерминации:\", score/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07198ad",
   "metadata": {},
   "source": [
    "Мы видим, что линейная регрессия показала гораздо лучший результат, чем K-ближайших соседей.\n",
    "Усредненный скор равен 73%, на максимуме доходил до 81%.\n",
    "\n",
    "Попробуем теперь подбор с использованием GridSearchCV. \n",
    "В качестве регрессора для начала используем \"случайный лес\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e4a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec07f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем модель-оценщик\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# произвольно зададим параметры регрессора для перебора в GridSearch\n",
    "parameters = { 'n_estimators': range (10, 51, 10),\n",
    "              'max_depth': range (1, 13, 2),\n",
    "              'min_samples_leaf': range (1, 8),\n",
    "              'min_samples_split': range (2, 10, 2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61d50d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': range(1, 13, 2),\n",
       "                         'min_samples_leaf': range(1, 8),\n",
       "                         'min_samples_split': range(2, 10, 2),\n",
       "                         'n_estimators': range(10, 51, 10)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# инициализируем и обучим GridSearchCV\n",
    "grid = GridSearchCV(model, parameters, cv=5)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e309b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем наилучшие параметры\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c24f814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642229127037207"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем наилучший скор\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c537bf15",
   "metadata": {},
   "source": [
    "Как видим, RandomForestRegressor даже в GridSearch отработал хуже, чем линейная регрессия в обычном цикле.\n",
    "\n",
    "Попробуем теперь использовать единичное дерево решений в качестве регрессора для GridSearch (вдруг окажется лучше, чем случайный лес?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a69e1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54961009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем модель-оценщик\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# произвольно зададим параметры регрессора для перебора в GridSearch,\n",
    "# используем те же параметры, что и в RandomForest (за исключением неактуального параметра 'n_estimators')\n",
    "parameters = {'max_depth': range (1, 13, 2),\n",
    "              'min_samples_leaf': range (1, 8),\n",
    "              'min_samples_split': range (2, 10, 2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19a04722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': range(1, 13, 2),\n",
       "                         'min_samples_leaf': range(1, 8),\n",
       "                         'min_samples_split': range(2, 10, 2)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# инициализируем и обучим GridSearchCV\n",
    "grid = GridSearchCV(model, parameters, cv=5)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69acea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем наилучшие параметры\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e958699c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5284134088528964"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем наилучший скор\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf426b8",
   "metadata": {},
   "source": [
    "Мы видим, что скор в случае использования DecisionTreeRegressor (единичного дерева) \n",
    "ожидаемо упал по сравнению со случайным лесом. \n",
    "Но следует отметить, что DecisionTreeRegressor отработал гораздо быстрее RandomForest'a, что логично.\n",
    "\n",
    "Полагаю, в случае ограниченности ресурсов лучше использовать сперва единичный DecisionTreeRegressor, \n",
    "и если результат не устраивает, то использовать RandomForest.\n",
    "\n",
    "Попробуем напоследок ExtraTreeRegressor с теми же параметрами, что DecisionTreeRegressor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ce62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import ExtraTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938c244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем модель-оценщик\n",
    "model = ExtraTreeRegressor()\n",
    "\n",
    "# произвольно зададим параметры регрессора для перебора в GridSearch,\n",
    "# используем те же параметры, что и в RandomForest (за исключением неактуального параметра 'n_estimators')\n",
    "parameters = {'max_depth': range (1, 13, 2),\n",
    "              'min_samples_leaf': range (1, 8),\n",
    "              'min_samples_split': range (2, 10, 2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dce8bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=ExtraTreeRegressor(),\n",
       "             param_grid={'max_depth': range(1, 13, 2),\n",
       "                         'min_samples_leaf': range(1, 8),\n",
       "                         'min_samples_split': range(2, 10, 2)})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# инициализируем и обучим GridSearchCV\n",
    "grid = GridSearchCV(model, parameters, cv=5)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7023c642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 4}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем наилучшие параметры\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8504c204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5778400002773444"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем наилучший скор\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b61bd3",
   "metadata": {},
   "source": [
    "Мы видим, что коэфф-т детерминации незначительно увеличился по сравнению с использованием DecisionTreeRegressor.\n",
    "\n",
    "Общий вывод: из использованных методов наилучшее качество предсказаний (на уровне 70-80%) показала линейная регрессия, \n",
    "далее  RandomForest (на уровне 65%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
