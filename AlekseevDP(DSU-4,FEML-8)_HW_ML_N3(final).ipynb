{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b209837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Алексеев Д.П. (DSU-4,FEML-8)\n",
    "# Домашнее задание к лекции «Функции потерь и оптимизация» (#3). Скорректированное\n",
    "\n",
    "# Задание:\n",
    "# Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "# Реализовать самостоятельно логистическую регрессию\n",
    "# Обучить ее методом градиентного спуска:\n",
    "# -Методом nesterov momentum\n",
    "# -Методом rmsprop\n",
    "\n",
    "# Дополнительное задание *\n",
    "# В качестве dataset’а взять Iris, оставив 2 класса:\n",
    "# Iris Versicolor\n",
    "# Iris Virginica\n",
    "\n",
    "# Примечание: если я правильно понял задание, \n",
    "# то необходимо реализовать \"вручную\" логистическую регрессию для предсказаний классов 'Iris Versicolor' и 'Iris Virginica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8944190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab8daca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем датасет с ирисами Фишера (сразу как датафрейм)\n",
    "iris = datasets.load_iris(as_frame = True).frame\n",
    "iris\n",
    "# 4 входящих (описательных) признака | sepal - чашелистик, petal - лепесток\n",
    "# значениe целевой переменной target (класс цветка): 'setosa' =0, 'versicolor'=1, 'virginica'=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb0e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "50                 7.0               3.2                4.7               1.4   \n",
       "51                 6.4               3.2                4.5               1.5   \n",
       "52                 6.9               3.1                4.9               1.5   \n",
       "53                 5.5               2.3                4.0               1.3   \n",
       "54                 6.5               2.8                4.6               1.5   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "50        1  \n",
       "51        1  \n",
       "52        1  \n",
       "53        1  \n",
       "54        1  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# по условию задачи, нам нужна классификация только 'versicolor' и 'virginica' ('versicolor'=1, 'virginica'=2)\n",
    "# Следовательно, строки с классом=0, т.е. 'setosa', можно выкинуть.\n",
    "iris = iris[iris['target'] != 0]\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41638d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "50                 7.0               3.2                4.7               1.4\n",
       "51                 6.4               3.2                4.5               1.5\n",
       "52                 6.9               3.1                4.9               1.5\n",
       "53                 5.5               2.3                4.0               1.3\n",
       "54                 6.5               2.8                4.6               1.5\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa7ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50     0\n",
       "51     0\n",
       "52     0\n",
       "53     0\n",
       "54     0\n",
       "      ..\n",
       "145    1\n",
       "146    1\n",
       "147    1\n",
       "148    1\n",
       "149    1\n",
       "Name: target, Length: 100, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем целевую переменную к бинарному виду: 'versicolor'= 1-1 =0, 'virginica'= 2-1 = 1\n",
    "Y = iris['target'] - 1\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c4a8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# По теоретическим описаниям логистической регрессии возникли сложности с написанием работающего кода, \n",
    "# поэтому код частично пришлось позаимствовать по ссылке:\n",
    "# https://pythobyte.com/logistic-regression-from-scratch-ae373d5d/\n",
    "\n",
    "# Опишем класс логистического регрессора, определяющий функции, необходимые для обучения модели и предсказаний\n",
    "class LogReg:\n",
    "    def __init__(self,x,y):      \n",
    "        self.intercept = np.ones((x.shape[0], 1))  \n",
    "        self.x = np.concatenate((self.intercept, x), axis=1)\n",
    "        self.weight = np.zeros(self.x.shape[1])\n",
    "        self.y = y\n",
    "        \n",
    "    # Функция сигмоиды\n",
    "    def sigmoid(self, x, weight):\n",
    "        z = np.dot(x, weight)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # Функция потерь\n",
    "    def loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    # Функция расчета градиента\n",
    "    def gradient_descent(self, xx, h, y):\n",
    "        return np.dot(xx.T, (h - y)) / y.shape[0]\n",
    "\n",
    "    # Функция обучения регрессора \"стандартным\" способом\n",
    "    def fit(self, lr , iterations):\n",
    "        for i in range(iterations):\n",
    "            # рассчитываем значение сигмоиды при текущих значениях весов признаков (w)\n",
    "            sigma = self.sigmoid(self.x, self.weight)\n",
    "            \n",
    "            # рассчитываем значение функции потерь при текущем значении сигмоиды\n",
    "            loss = self.loss(sigma, self.y)\n",
    "            \n",
    "            # рассчитываем шаг градиентного спуска\n",
    "            dW = self.gradient_descent(self.x , sigma, self.y)\n",
    "            \n",
    "            # обновляем веса признаков с учетом заданного learning rate и рассчитанного шага градиентного спуска\n",
    "            self.weight -= lr * dW\n",
    "            print('Текущие веса признаков: ', self.weight)\n",
    "            \n",
    "        return print('Обучение модели закончено')\n",
    "    \n",
    "    # Функция обучения регрессора методом \"Nesterov Momentum\"\n",
    "    def fit_nesterov(self, lr, iterations, imp):\n",
    "        vx = np.zeros(self.x.shape[1])\n",
    "\n",
    "        for i in range(iterations):\n",
    "            sigma = self.sigmoid(self.x, self.weight)            \n",
    "            \n",
    "            dW = self.gradient_descent(self.x , sigma, self.y)\n",
    "            \n",
    "            #Обновляем накопленные вектора\n",
    "            vx = imp * vx - lr * dW\n",
    "            old_vx = vx\n",
    "            \n",
    "            #Обновляем веса\n",
    "            self.weight = imp * old_vx + (1 - imp) * vx\n",
    "            print('Текущие веса признаков: ', self.weight)\n",
    "            \n",
    "        return print('Обучение модели закончено')\n",
    "    \n",
    "    # Функция обучения регрессора методом \"RMSProp\"\n",
    "    def fit_rmsprop(self, lr, iterations, imp, eps):\n",
    "        eps_dW = np.zeros(self.x.shape[1])\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            sigma = self.sigmoid(self.x, self.weight)            \n",
    "            \n",
    "            dW = self.gradient_descent(self.x , sigma, self.y)\n",
    "            \n",
    "            #Обновляем накопленные вектора\n",
    "            old_eps_dW = eps_dW\n",
    "            eps_dW = imp*old_eps_dW + (1 - imp)*dW**2\n",
    "            \n",
    "            #Обновляем веса\n",
    "            self.weight += -(lr * (1 / np.sqrt(eps_dW + eps)))*dW\n",
    "            print('Текущие веса признаков: ', self.weight)\n",
    "    \n",
    "        return print('Обучение модели закончено')\n",
    "\n",
    "    # Функция предсказания метки класса\n",
    "    def predict(self, x_new , treshold):\n",
    "        x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "        result = self.sigmoid(x_new, self.weight)\n",
    "        result = result >= treshold\n",
    "        y_pred = np.zeros(result.shape[0])\n",
    "        for i in range(len(y_pred)):\n",
    "            if result[i] == True: \n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        return y_pred            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b851827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текущие веса признаков:  [0.     0.0163 0.0051 0.0323 0.0175]\n",
      "Текущие веса признаков:  [-0.00755108 -0.01529732 -0.01169392  0.02670416  0.02196683]\n",
      "Текущие веса признаков:  [-0.00832341 -0.00402241 -0.00887163  0.05482076  0.03796999]\n",
      "Текущие веса признаков:  [-0.01511587 -0.03094459 -0.02350778  0.05269899  0.04356872]\n",
      "Текущие веса признаков:  [-0.01649384 -0.02363706 -0.02247979  0.07746943  0.05836308]\n",
      "Текущие веса признаков:  [-0.02267477 -0.04681455 -0.03538385  0.07808912  0.06484273]\n",
      "Текущие веса признаков:  [-0.02453043 -0.04266201 -0.03577894  0.1001572   0.07864997]\n",
      "Текущие веса признаков:  [-0.03021418 -0.06281771 -0.04728169  0.10294989  0.085816  ]\n",
      "Текущие веса признаков:  [-0.0324472  -0.06118283 -0.04880871  0.12282127  0.09881041]\n",
      "Текущие веса признаков:  [-0.03772425 -0.07888858 -0.05917187  0.12733796  0.10650934]\n",
      "Текущие веса признаков:  [-0.04025481 -0.07926397 -0.06159907  0.14541572  0.11882999]\n",
      "Текущие веса признаков:  [-0.0451977  -0.09497779 -0.07103232  0.15129739  0.12693926]\n",
      "Текущие веса признаков:  [-0.04796166 -0.0969555  -0.07417343  0.16790613  0.13869828]\n",
      "Текущие веса признаков:  [-0.05262903 -0.11104732 -0.08284617  0.17486336  0.14711925]\n",
      "Текущие веса признаков:  [-0.05557452 -0.1142972  -0.08655048  0.19026624  0.15840769]\n",
      "Текущие веса признаков:  [-0.06001403 -0.12706743 -0.09460033  0.19806452  0.16706058]\n",
      "Текущие веса признаков:  [-0.06309898 -0.13132129 -0.09874547  0.21247578  0.17795266]\n",
      "Текущие веса признаков:  [-0.06734949 -0.1430146  -0.10628456  0.22092466  0.18677281]\n",
      "Текущие веса признаков:  [-0.0705397  -0.14805425 -0.110771    0.23451905  0.19732922]\n",
      "Текущие веса признаков:  [-0.07463295 -0.15887013 -0.11789081  0.24346373  0.20626423]\n",
      "Текущие веса признаков:  [-0.07790065 -0.16451811 -0.12263765  0.25638384  0.2165346 ]\n",
      "Текущие веса признаков:  [-0.08186255 -0.17461913 -0.12941277  0.26569869  0.22554207]\n",
      "Текущие веса признаков:  [-0.08518522 -0.18073138 -0.13435438  0.27806076  0.23556698]\n",
      "Текущие веса признаков:  [-0.08903689 -0.19024974 -0.14084553  0.28764409  0.24461274]\n",
      "Текущие веса признаков:  [-0.09239638 -0.1967097  -0.14592885  0.29954262  0.25442531]\n",
      "Текущие веса признаков:  [-0.09615498 -0.20575261 -0.1521853   0.3093125   0.26348196]\n",
      "Текущие веса признаков:  [-0.09953671 -0.21246641 -0.15736764  0.32082411  0.27310917]\n",
      "Текущие веса признаков:  [-0.10321615 -0.22112043 -0.16342923  0.33071485  0.28215488]\n",
      "Текущие веса признаков:  [-0.10660849 -0.22801291 -0.16867647  0.34190137  0.29161863]\n",
      "Текущие веса признаков:  [-0.11021999 -0.2363476  -0.17457525  0.35186073  0.30063618]\n",
      "Текущие веса признаков:  [-0.11361374 -0.24335902 -0.17986031  0.36277182  0.30995421]\n",
      "Текущие веса признаков:  [-0.11716631 -0.25142994 -0.18562194  0.37275856  0.31893015]\n",
      "Текущие веса признаков:  [-0.12055428 -0.2585132  -0.19092351  0.38343391  0.32811675]\n",
      "Текущие веса признаков:  [-0.12405512 -0.26636446 -0.19656842  0.39341582  0.33704074]\n",
      "Текущие веса признаков:  [-0.12743173 -0.27348278 -0.20186992  0.40388695  0.34610741]\n",
      "Текущие веса признаков:  [-0.13088658 -0.28114918 -0.20741426  0.41383916  0.3549716 ]\n",
      "Текущие веса признаков:  [-0.13424757 -0.28827416 -0.21270294  0.424131    0.36392756]\n",
      "Текущие веса признаков:  [-0.13766097 -0.29578295 -0.21815941  0.43403455  0.37272615]\n",
      "Текущие веса признаков:  [-0.14100315 -0.30289292 -0.22342559  0.44416668  0.3815788 ]\n",
      "Текущие веса признаков:  [-0.14437868 -0.31026532 -0.22880414  0.45400736  0.39030758]\n",
      "Текущие веса признаков:  [-0.14769971 -0.31734399 -0.2340406   0.46399512  0.39906284]\n",
      "Текущие веса признаков:  [-0.15104018 -0.3245964  -0.23934897  0.47376251  0.40771893]\n",
      "Текущие веса признаков:  [-0.15433839 -0.33163173 -0.24455044  0.48361785  0.41638157]\n",
      "Текущие веса признаков:  [-0.15764603 -0.33877677 -0.24979462  0.49330449  0.42496307]\n",
      "Текущие веса признаков:  [-0.16092026 -0.34576004 -0.25495734  0.50303674  0.43353695]\n",
      "Текущие веса признаков:  [-0.16419683 -0.35280738 -0.260142    0.51263744  0.44204274]\n",
      "Текущие веса признаков:  [-0.16744634 -0.35973246 -0.26526337  0.52225388  0.45053102]\n",
      "Текущие веса признаков:  [-0.17069322 -0.3666895  -0.27039211  0.53176525  0.45896059]\n",
      "Текущие веса признаков:  [-0.17391757 -0.37355219 -0.27547046  0.54127158  0.46736586]\n",
      "Текущие веса признаков:  [-0.17713589 -0.3804246  -0.2805461   0.55069155  0.47571916]\n",
      "Текущие веса признаков:  [-0.18033486 -0.3872222  -0.2855804   0.5600923   0.48404362]\n",
      "Текущие веса признаков:  [-0.18352552 -0.39401435 -0.29060517  0.56941981  0.49232092]\n",
      "Текущие веса признаков:  [-0.18669908 -0.40074524 -0.2955949   0.57871861  0.50056646]\n",
      "Текущие веса признаков:  [-0.18986283 -0.40746055 -0.30057056  0.58795332  0.50876827]\n",
      "Текущие веса признаков:  [-0.19301108 -0.41412392 -0.30551556  0.59715314  0.51693653]\n",
      "Текущие веса признаков:  [-0.19614856 -0.42076508 -0.31044357  0.60629525  0.52506356]\n",
      "Текущие веса признаков:  [-0.19927166 -0.42736069 -0.31534396  0.61539858  0.533156  ]\n",
      "Текущие веса признаков:  [-0.20238343 -0.43392989 -0.32022552  0.62444867  0.54120907]\n",
      "Текущие веса признаков:  [-0.20548161 -0.44045792 -0.32508157  0.63345766  0.54922705]\n",
      "Текущие веса признаков:  [-0.20856818 -0.44695697 -0.32991773  0.64241655  0.55720704]\n",
      "Текущие веса признаков:  [-0.21164172 -0.45341788 -0.33472986  0.65133308  0.56515183]\n",
      "Текущие веса признаков:  [-0.21470352 -0.45984833 -0.33952153  0.66020179  0.57305969]\n",
      "Текущие веса признаков:  [-0.21775274 -0.46624277 -0.34429025  0.66902759  0.58093246]\n",
      "Текущие веса признаков:  [-0.22079019 -0.47260599 -0.34903825  0.67780724  0.58876918]\n",
      "Текущие веса признаков:  [-0.2238154  -0.47893473 -0.3537641   0.68654388  0.59657106]\n",
      "Текущие веса признаков:  [-0.2268289  -0.48523197 -0.35846921  0.69523568  0.60433764]\n",
      "Текущие веса признаков:  [-0.22983044 -0.49149585 -0.36315277  0.70388464  0.61206973]\n",
      "Текущие веса признаков:  [-0.23282036 -0.49772826 -0.3678157   0.71248982  0.61976716]\n",
      "Текущие веса признаков:  [-0.23579856 -0.5039282  -0.37245759  0.72105254  0.62743052]\n",
      "Текущие веса признаков:  [-0.23876528 -0.51009686 -0.37707903  0.72957236  0.63505982]\n",
      "Текущие веса признаков:  [-0.24172049 -0.51623376 -0.38167985  0.73805019  0.64265549]\n",
      "Текущие веса признаков:  [-0.24466435 -0.52233971 -0.38626046  0.74648593  0.65021764]\n",
      "Текущие веса признаков:  [-0.24759689 -0.52841453 -0.39082083  0.75488021  0.65774663]\n",
      "Текущие веса признаков:  [-0.25051825 -0.53445877 -0.39536125  0.76323312  0.66524263]\n",
      "Текущие веса признаков:  [-0.25342846 -0.54047243 -0.39988178  0.77154515  0.67270594]\n",
      "Текущие веса признаков:  [-0.25632765 -0.54645593 -0.40438265  0.77981648  0.68013675]\n",
      "Текущие веса признаков:  [-0.25921587 -0.55240937 -0.40886394  0.78804753  0.68753535]\n",
      "Текущие веса признаков:  [-0.26209322 -0.55833309 -0.41332586  0.79623853  0.69490196]\n",
      "Текущие веса признаков:  [-0.26495977 -0.56422723 -0.41776852  0.80438984  0.70223681]\n",
      "Текущие веса признаков:  [-0.2678156  -0.57009209 -0.42219209  0.81250173  0.70954015]\n",
      "Текущие веса признаков:  [-0.2706608  -0.57592785 -0.42659671  0.82057453  0.7168122 ]\n",
      "Текущие веса признаков:  [-0.27349545 -0.58173477 -0.43098252  0.82860851  0.72405321]\n",
      "Текущие веса признаков:  [-0.27631962 -0.58751304 -0.43534967  0.836604    0.73126339]\n",
      "Текущие веса признаков:  [-0.27913339 -0.59326291 -0.4396983   0.84456128  0.73844299]\n",
      "Текущие веса признаков:  [-0.28193683 -0.59898458 -0.44402856  0.85248064  0.74559222]\n",
      "Текущие веса признаков:  [-0.28473004 -0.60467829 -0.44834058  0.86036237  0.75271131]\n",
      "Текущие веса признаков:  [-0.28751307 -0.61034423 -0.45263451  0.86820676  0.75980048]\n",
      "Текущие веса признаков:  [-0.29028601 -0.61598264 -0.45691048  0.8760141   0.76685996]\n",
      "Текущие веса признаков:  [-0.29304894 -0.62159371 -0.46116862  0.88378467  0.77388996]\n",
      "Текущие веса признаков:  [-0.29580191 -0.62717767 -0.46540909  0.89151875  0.7808907 ]\n",
      "Текущие веса признаков:  [-0.29854502 -0.63273471 -0.469632    0.89921662  0.78786241]\n",
      "Текущие веса признаков:  [-0.30127833 -0.63826505 -0.47383749  0.90687855  0.79480528]\n",
      "Текущие веса признаков:  [-0.30400191 -0.6437689  -0.4780257   0.91450483  0.80171954]\n",
      "Текущие веса признаков:  [-0.30671584 -0.64924645 -0.48219676  0.92209571  0.80860539]\n",
      "Текущие веса признаков:  [-0.30942019 -0.65469791 -0.48635079  0.92965147  0.81546304]\n",
      "Текущие веса признаков:  [-0.31211502 -0.66012347 -0.49048792  0.93717238  0.8222927 ]\n",
      "Текущие веса признаков:  [-0.31480041 -0.66552335 -0.49460829  0.9446587   0.82909458]\n",
      "Текущие веса признаков:  [-0.31747642 -0.67089772 -0.49871201  0.95211069  0.83586888]\n",
      "Текущие веса признаков:  [-0.32014313 -0.6762468  -0.50279922  0.95952861  0.8426158 ]\n",
      "Текущие веса признаков:  [-0.32280061 -0.68157076 -0.50687004  0.96691272  0.84933553]\n",
      "Обучение модели закончено\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "iterations = 100\n",
    "\n",
    "# создадим регрессор, на трейн/тест выборки разбивать не будем\n",
    "regressor = LogReg(X, Y)\n",
    "\n",
    "# обучим регрессор\n",
    "regressor.fit(lr, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3db393e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим качество предсказаний, возьмем порог 0.5\n",
    "y_pred = regressor.predict(X, 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08502ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', sum(y_pred == Y) / Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c83ec",
   "metadata": {},
   "source": [
    "Точность 0.96 - неплохой результат.\n",
    "Попробуем теперь обучить модель методом Нестеров Моментум на тех же параметрах (lr = 0.1, iterations = 100).\n",
    "Коэфф-т сохранения импульса возьмем равным 0.98."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "309af6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текущие веса признаков:  [0.     0.0163 0.0051 0.0323 0.0175]\n",
      "Текущие веса признаков:  [-0.00755108 -0.01562332 -0.01179592  0.02605816  0.02161683]\n",
      "Текущие веса признаков:  [-0.00802018 -0.00307031 -0.00829634  0.05441769  0.03745046]\n",
      "Текущие веса признаков:  [-0.01477648 -0.03071392 -0.02312521  0.05059664  0.04209242]\n",
      "Текущие веса признаков:  [-0.01561159 -0.0212174  -0.02091579  0.0756104   0.05647925]\n",
      "Текущие веса признаков:  [-0.02168319 -0.04524261 -0.03398527  0.07373582  0.06149837]\n",
      "Текущие веса признаков:  [-0.02280324 -0.03825339 -0.03282013  0.09588463  0.07461815]\n",
      "Текущие веса признаков:  [-0.02828053 -0.05919851 -0.04438143  0.09557719  0.07989842]\n",
      "Текущие веса признаков:  [-0.02962046 -0.05427053 -0.04406156  0.11525814  0.09190145]\n",
      "Текущие веса признаков:  [-0.03457908 -0.07258193 -0.05432361  0.11620901  0.0973504 ]\n",
      "Текущие веса признаков:  [-0.03608589 -0.06934723 -0.05468551  0.13375528  0.10836436]\n",
      "Текущие веса признаков:  [-0.04059    -0.08540011 -0.06382446  0.13570974  0.11390749]\n",
      "Текущие веса признаков:  [-0.04222011 -0.08355189 -0.06473235  0.15140407  0.1240421 ]\n",
      "Текущие веса признаков:  [-0.04632466 -0.09766459 -0.07289813  0.15415027  0.12961898]\n",
      "Текущие веса признаков:  [-0.04804201 -0.09694525 -0.07423851  0.16823449  0.13896927]\n",
      "Текущие веса признаков:  [-0.05179437 -0.10938958 -0.08155958  0.17159538  0.14453085]\n",
      "Текущие веса признаков:  [-0.05356906 -0.10958201 -0.08323723  0.18427739  0.15317961]\n",
      "Текущие веса признаков:  [-0.05701026 -0.1205909  -0.08982405  0.18810473  0.15868614]\n",
      "Текущие веса признаков:  [-0.05881753 -0.1215119  -0.09175908  0.19956379  0.16670574]\n",
      "Текущие веса признаков:  [-0.06198319 -0.13128532 -0.09770687  0.20373359  0.17212527]\n",
      "Текущие веса признаков:  [-0.06380262 -0.13278047 -0.09983233  0.21412445  0.17957915]\n",
      "Текущие веса признаков:  [-0.06672371 -0.14149011 -0.10522317  0.21853333  0.18488625]\n",
      "Текущие веса признаков:  [-0.06853857 -0.1434296  -0.1074832   0.22798963  0.19183008]\n",
      "Текущие веса признаков:  [-0.071242   -0.15122279 -0.11238788  0.2325518   0.1970049 ]\n",
      "Текущие веса признаков:  [-0.07303872 -0.15349795 -0.11473609  0.24118891  0.20348756]\n",
      "Текущие веса признаков:  [-0.07554792 -0.16050089 -0.11921557  0.24583373  0.20851495]\n",
      "Текущие веса признаков:  [-0.07731561 -0.16302128 -0.12161376  0.25375111  0.21457944]\n",
      "Текущие веса признаков:  [-0.07965094 -0.16934187 -0.12572045  0.25842087  0.21944825]\n",
      "Текущие веса признаков:  [-0.08138104 -0.17203272 -0.12813743  0.26570418  0.22513237]\n",
      "Текущие веса признаков:  [-0.08356018 -0.17776303 -0.13191637  0.27035231  0.22983482]\n",
      "Текущие веса признаков:  [-0.08524609 -0.18056299 -0.13432693  0.27707525  0.23517185]\n",
      "Текущие веса признаков:  [-0.08728443 -0.18578138 -0.13781675  0.28166463  0.23970303]\n",
      "Текущие веса признаков:  [-0.0889212  -0.18864062 -0.14020081  0.28789053  0.24472229]\n",
      "Текущие веса признаков:  [-0.09083212 -0.19341366 -0.1434346   0.2923921   0.24907965]\n",
      "Текущие веса признаков:  [-0.09241622 -0.19629211 -0.14577641  0.29817536  0.25380702]\n",
      "Текущие веса признаков:  [-0.09421135 -0.20067628 -0.14878251  0.30256683  0.25798996]\n",
      "Текущие веса признаков:  [-0.09574041 -0.20354211 -0.15106998  0.30795418  0.26244835]\n",
      "Текущие веса признаков:  [-0.09742989 -0.20758524 -0.15387267  0.31221894  0.26645787]\n",
      "Текущие веса признаков:  [-0.0989025  -0.21041358 -0.15609674  0.31725053  0.27066756]\n",
      "Текущие веса признаков:  [-0.1004952  -0.21415615 -0.15871681  0.32137668  0.27450595]\n",
      "Текущие веса признаков:  [-0.10191075 -0.21692788 -0.16087097  0.32608707  0.27848501]\n",
      "Текущие веса признаков:  [-0.10341442 -0.22040417 -0.16332626  0.33006658  0.28215557]\n",
      "Текущие веса признаков:  [-0.10477294 -0.22310497 -0.16540605  0.33448558  0.2859201 ]\n",
      "Текущие веса признаков:  [-0.1061944  -0.22634403 -0.16771192  0.33831359  0.28942693]\n",
      "Текущие веса признаков:  [-0.10749641 -0.22896347 -0.16971459  0.34246695  0.29299137]\n",
      "Текущие веса признаков:  [-0.10884169 -0.23198995 -0.17188427  0.34614115  0.29633914]\n",
      "Текущие веса признаков:  [-0.11008812 -0.2345208  -0.17380841  0.35005124  0.2997165 ]\n",
      "Текущие веса признаков:  [-0.11136254 -0.23735567 -0.17585335  0.35357134  0.30291029]\n",
      "Текущие веса признаков:  [-0.11255463 -0.23979327 -0.17769867  0.35725765  0.30611231]\n",
      "Текущие веса признаков:  [-0.11376295 -0.24245444 -0.17962883  0.36062495  0.30915753]\n",
      "Текущие веса признаков:  [-0.11490216 -0.24479618 -0.18139584  0.36410456  0.31219488]\n",
      "Текущие веса признаков:  [-0.11604864 -0.24729899 -0.18321995  0.36732159  0.31509708]\n",
      "Текущие веса признаков:  [-0.1171366  -0.24954386 -0.18490983  0.37060953  0.3179795 ]\n",
      "Текущие веса признаков:  [-0.11822507 -0.25190157 -0.18663555  0.37367973  0.32074434]\n",
      "Текущие веса признаков:  [-0.11926352 -0.2540498  -0.18824999  0.37678935  0.32348074]\n",
      "Текущие веса признаков:  [-0.12029745 -0.25627391 -0.18988409  0.37971686  0.32611387]\n",
      "Текущие веса признаков:  [-0.1212882  -0.25832671 -0.19142512  0.38266004  0.32871248]\n",
      "Текущие веса признаков:  [-0.12227077 -0.26042723 -0.19297365  0.38544945  0.33121952]\n",
      "Текущие веса признаков:  [-0.12321567 -0.26238652 -0.19444357  0.38823687  0.33368793]\n",
      "Текущие веса признаков:  [-0.12414976 -0.26437228 -0.19591195  0.39089312  0.3360744 ]\n",
      "Текущие веса признаков:  [-0.12505065 -0.26624052 -0.19731323  0.3935344   0.33841965]\n",
      "Текущие веса признаков:  [-0.12593894 -0.26811933 -0.19870634  0.3960626   0.34069095]\n",
      "Текущие веса признаков:  [-0.12679768 -0.26989933 -0.20004156  0.39856652  0.3429196 ]\n",
      "Текущие веса признаков:  [-0.12764263 -0.27167817 -0.20136385  0.40097188  0.345081  ]\n",
      "Текущие веса признаков:  [-0.12846103 -0.27337301 -0.20263562  0.40334644  0.34719918]\n",
      "Текущие веса признаков:  [-0.12926493 -0.27505814 -0.20389116  0.40563417  0.34925575]\n",
      "Текущие веса признаков:  [-0.13004476 -0.27667104 -0.20510213  0.40788672  0.35126919]\n",
      "Текущие веса признаков:  [-0.13080974 -0.27826815 -0.20629464  0.41006199  0.35322585]\n",
      "Текущие веса признаков:  [-0.13155274 -0.27980243 -0.20744743  0.41219933  0.35513994]\n",
      "Текущие веса признаков:  [-0.1322808  -0.28131668 -0.20858036  0.41426723  0.3570014 ]\n",
      "Текущие веса признаков:  [-0.13298863 -0.28277566 -0.20967755  0.41629565  0.35882121]\n",
      "Текущие веса признаков:  [-0.13368164 -0.28421181 -0.2107541   0.41826113  0.36059202]\n",
      "Текущие веса признаков:  [-0.13435593 -0.28559879 -0.21179819  0.42018649  0.36232232]\n",
      "Текущие веса признаков:  [-0.13501565 -0.2869612  -0.21282134  0.42205437  0.36400682]\n",
      "Текущие веса признаков:  [-0.13565795 -0.28827944 -0.21381479  0.42388215  0.36565212]\n",
      "Текущие веса признаков:  [-0.13628603 -0.28957216 -0.21478731  0.42565707  0.36725447]\n",
      "Текущие веса признаков:  [-0.13689784 -0.29082486 -0.21573248  0.4273924   0.36881903]\n",
      "Текущие веса признаков:  [-0.13749584 -0.29205165 -0.21665699  0.42907884  0.3703432 ]\n",
      "Текущие веса признаков:  [-0.13807859 -0.29324188 -0.21755616  0.43072653  0.37183104]\n",
      "Текущие веса признаков:  [-0.138648   -0.29440626 -0.21843511  0.43232877  0.37328082]\n",
      "Текущие веса признаков:  [-0.13920306 -0.29553701 -0.21929047  0.43389337  0.37469577]\n",
      "Текущие веса признаков:  [-0.13974527 -0.29664227 -0.22012617  0.43541554  0.37607479]\n",
      "Текущие веса признаков:  [-0.14027395 -0.29771641 -0.22093982  0.43690131  0.37742046]\n",
      "Текущие веса признаков:  [-0.14079029 -0.29876564 -0.22173445  0.43834733  0.37873215]\n",
      "Текущие веса признаков:  [-0.14129385 -0.29978593 -0.22250839  0.43975831  0.38001197]\n",
      "Текущие веса признаков:  [-0.14178557 -0.30078204 -0.223264    0.44113195  0.38125962]\n",
      "Текущие веса признаков:  [-0.1422652  -0.30175111 -0.22400016  0.44247194  0.38247684]\n",
      "Текущие веса признаков:  [-0.1427335  -0.30269684 -0.22471871  0.44377678  0.38366358]\n",
      "Текущие веса признаков:  [-0.14319033 -0.30361723 -0.22541891  0.4450494   0.3848213 ]\n",
      "Текущие веса признаков:  [-0.14363634 -0.30451516 -0.22610224  0.44628886  0.38595011]\n",
      "Текущие веса признаков:  [-0.14407148 -0.30538929 -0.22676824  0.44749752  0.38705125]\n",
      "Текущие веса признаков:  [-0.14449626 -0.30624186 -0.2274181   0.44867485  0.38812496]\n",
      "Текущие веса признаков:  [-0.14491073 -0.30707201 -0.22805156  0.44982278  0.3891723 ]\n",
      "Текущие веса признаков:  [-0.14531533 -0.30788154 -0.2286696   0.45094109  0.39019361]\n",
      "Текущие веса признаков:  [-0.14571012 -0.30866992 -0.22927212  0.45203135  0.3911898 ]\n",
      "Текущие веса признаков:  [-0.14609549 -0.30943859 -0.22985991  0.45309357  0.39216127]\n",
      "Текущие веса признаков:  [-0.14647154 -0.31018728 -0.23043299  0.45412908  0.39310883]\n",
      "Текущие веса признаков:  [-0.1468386  -0.31091716 -0.23099203  0.45513802  0.39403289]\n",
      "Текущие веса признаков:  [-0.14719681 -0.31162815 -0.23153711  0.45612153  0.3949342 ]\n",
      "Текущие веса признаков:  [-0.14754646 -0.31232121 -0.23206881  0.45707986  0.39581319]\n",
      "Обучение модели закончено\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "iterations = 100\n",
    "impulse = 0.98 \n",
    "\n",
    "# создадим регрессор отдельно под Нестеров Моментум\n",
    "regressor_NM = LogReg(X, Y)\n",
    "\n",
    "# обучим регрессор методом Нестеров Моментум\n",
    "regressor_NM.fit_nesterov(lr, iterations, impulse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be148279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим качество предсказаний, возьмем порог 0.5\n",
    "y_pred = regressor_NM.predict(X, 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea88668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.92\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', sum(y_pred == Y) / Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0070497",
   "metadata": {},
   "source": [
    "Мы видим, что точность предсказаний незначительно снизилась по сравнению с обычным способом (с 0.96 до 0.92), \n",
    "но качество модели всё еще осталось высоким.\n",
    "\n",
    "Попробуем теперь оптимизацию методом RMSProp. Параметр epsilon для избежания деления на ноль возьмем равным 0.00001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9293ee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текущие веса признаков:  [0.         0.70054575 0.64759621 0.70541843 0.70140421]\n",
      "Текущие веса признаков:  [-0.70640061 -0.00549816 -0.05894919  0.00618602  0.01763495]\n",
      "Текущие веса признаков:  [-0.44102053  0.30183348  0.23539464  0.3758326   0.44314053]\n",
      "Текущие веса признаков:  [-0.92086932 -0.17044206 -0.23961615 -0.07913139  0.01205103]\n",
      "Текущие веса признаков:  [-0.54139859  0.23486389  0.15772888  0.36193233  0.48303864]\n",
      "Текущие веса признаков:  [-0.89197926 -0.10380488 -0.18497937  0.04529791  0.19168488]\n",
      "Текущие веса признаков:  [-0.66603114  0.14263796  0.05516693  0.32075177  0.49237867]\n",
      "Текущие веса признаков:  [-0.94883302 -0.12909022 -0.22038917  0.06944477  0.26389591]\n",
      "Текущие веса признаков:  [-7.40154322e-01  9.75300591e-02  6.90764721e-04  3.21408994e-01\n",
      "  5.37766990e-01]\n",
      "Текущие веса признаков:  [-0.98111369 -0.13285038 -0.23335875  0.1102952   0.34776053]\n",
      "Текущие веса признаков:  [-0.80910336  0.05517862 -0.05030185  0.32111207  0.5783341 ]\n",
      "Текущие веса признаков:  [-1.01447244 -0.14010637 -0.24910784  0.14410015  0.42104408]\n",
      "Текущие веса признаков:  [-0.86630301  0.02280503 -0.09079457  0.32807907  0.62327451]\n",
      "Текущие веса признаков:  [-1.04627084 -0.14743958 -0.26444518  0.17535179  0.48924246]\n",
      "Текущие веса признаков:  [-0.91754706 -0.00492157 -0.12625046  0.33766988  0.66869244]\n",
      "Текущие веса признаков:  [-1.07758571 -0.15551144 -0.28015698  0.20400506  0.55292116]\n",
      "Текущие веса признаков:  [-0.96431511 -0.02916217 -0.15792589  0.34919754  0.71438616]\n",
      "Текущие веса признаков:  [-1.10869963 -0.16430645 -0.29631799  0.23051194  0.61296161]\n",
      "Текущие веса признаков:  [-1.00773475 -0.05081352 -0.18678736  0.36210817  0.76015201]\n",
      "Текущие веса признаков:  [-1.13974699 -0.17374652 -0.312915    0.25526188  0.6700603 ]\n",
      "Текущие веса признаков:  [-1.04857053 -0.07047146 -0.21348228  0.37605668  0.80590017]\n",
      "Текущие веса признаков:  [-1.17079713 -0.18374609 -0.32991005  0.27856759  0.72475472]\n",
      "Текущие веса признаков:  [-1.0873643  -0.08855294 -0.23846602  0.39081219  0.85158901]\n",
      "Текущие веса признаков:  [-1.20188489 -0.19422526 -0.34725863  0.30067743  0.77746066]\n",
      "Текущие веса признаков:  [-1.12451371 -0.10536216 -0.26207169  0.40620998  0.8971961 ]\n",
      "Текущие веса признаков:  [-1.23302434 -0.20511206 -0.36491532  0.32178983  0.82850282]\n",
      "Текущие веса признаков:  [-1.16031877 -0.12112874 -0.28455075  0.42212586  0.94270527]\n",
      "Текущие веса признаков:  [-1.26421587 -0.21634175 -0.3828355   0.34206516  0.87813773]\n",
      "Текущие веса признаков:  [-1.19501141 -0.13603127 -0.3060983   0.43846131  0.98810078]\n",
      "Текущие веса признаков:  [-1.29545011 -0.22785539 -0.40097543  0.36163511  0.92657081]\n",
      "Текущие веса признаков:  [-1.22877505 -0.15021269 -0.3268698   0.4551343   1.03336441]\n",
      "Текущие веса признаков:  [-1.32671006 -0.2395981  -0.41929176  0.38060989  0.97396899]\n",
      "Текущие веса признаков:  [-1.26175825 -0.16379092 -0.34699256  0.4720732   1.0784739 ]\n",
      "Текущие веса признаков:  [-1.35797237 -0.25151771 -0.43774099  0.39908366  1.0204701 ]\n",
      "Текущие веса признаков:  [-1.29408424 -0.17686621 -0.36657379  0.48921264  1.12340218]\n",
      "Текущие веса признаков:  [-1.38920829 -0.26356361 -0.45627894  0.41713859  1.06618972]\n",
      "Текущие веса признаков:  [-1.32585752 -0.18952615 -0.3857061   0.50649097  1.16811715]\n",
      "Текущие веса признаков:  [-1.42038459 -0.2756863  -0.47486076  0.43484744  1.1112259 ]\n",
      "Текущие веса признаков:  [-1.35716816 -0.20184868 -0.40447094  0.52384901  1.21258225]\n",
      "Текущие веса признаков:  [-1.45146486 -0.28783761 -0.49344151  0.452275    1.15566216]\n",
      "Текущие веса признаков:  [-1.38809414 -0.21390358 -0.42294031  0.54123003  1.25675778]\n",
      "Текущие веса признаков:  [-1.48241138 -0.29997166 -0.51197736  0.4694784   1.19956906]\n",
      "Текущие веса признаков:  [-1.4187022  -0.22575248 -0.44117711  0.55858086  1.30060298]\n",
      "Текущие веса признаков:  [-1.51318727 -0.31204642 -0.53042739  0.48650669  1.24300483]\n",
      "Текущие веса признаков:  [-1.44904775 -0.23744808 -0.45923451  0.57585367  1.34407872]\n",
      "Текущие веса признаков:  [-1.54375899 -0.32402545 -0.54875562  0.50340003  1.28601548]\n",
      "Текущие веса признаков:  [-1.47917441 -0.24903302 -0.47715509  0.59300808  1.3871504 ]\n",
      "Текущие веса признаков:  [-1.57409855 -0.33587963 -0.56693279  0.52018896  1.32863505]\n",
      "Текущие веса признаков:  [-1.50911369 -0.26053899 -0.4949701   0.61001289  1.42979044]\n",
      "Текущие веса признаков:  [-1.60418522 -0.34758816 -0.58493767  0.53689424  1.37088624]\n",
      "Текущие веса признаков:  [-1.53888545 -0.27198652 -0.51269947  0.6268471   1.47198004]\n",
      "Текущие веса признаков:  [-1.63400635 -0.35913892 -0.60275757  0.55352732  1.41278176]\n",
      "Текущие веса признаков:  [-1.56849907 -0.28338576 -0.53035273  0.64349995  1.51370996]\n",
      "Текущие веса признаков:  [-1.66355733 -0.3705279  -0.62038791  0.57009167  1.45432628]\n",
      "Текущие веса признаков:  [-1.59795547 -0.29473801 -0.54793066  0.6599699   1.55498013]\n",
      "Текущие веса признаков:  [-1.69284079 -0.38175796 -0.6378311   0.58658451  1.49551878]\n",
      "Текущие веса признаков:  [-1.62724955 -0.3060379  -0.56542763  0.67626296  1.59579846]\n",
      "Текущие веса признаков:  [-1.72186516 -0.39283718 -0.655095    0.60299887  1.53635492]\n",
      "Текущие веса признаков:  [-1.65637269 -0.31727575 -0.58283391  0.69239053  1.63617906]\n",
      "Текущие веса признаков:  [-1.75064306 -0.40377707 -0.67219114  0.61932554  1.57682921]\n",
      "Текущие веса признаков:  [-1.685315   -0.32843982 -0.600138    0.70836732  1.6761403 ]\n",
      "Текущие веса признаков:  [-1.77918962 -0.41459087 -0.68913306  0.63555481  1.61693674]\n",
      "Текущие веса признаков:  [-1.71406715 -0.33951813 -0.6173284   0.72420937  1.71570288]\n",
      "Текущие веса признаков:  [-1.80752104 -0.42529214 -0.70593486  0.6516777   1.65667429]\n",
      "Текущие веса признаков:  [-1.7426216  -0.35049989 -0.63439503  0.7399325   1.75488822]\n",
      "Текущие веса признаков:  [-1.83565333 -0.43589368 -0.72261006  0.66768689  1.69604109]\n",
      "Текущие веса признаков:  [-1.77097337 -0.36137638 -0.65133001  0.75555122  1.79371708]\n",
      "Текущие веса признаков:  [-1.86360145 -0.44640679 -0.73917081  0.68357718  1.73503903]\n",
      "Текущие веса признаков:  [-1.79912028 -0.37214142 -0.66812813  0.77107795  1.83220869]\n",
      "Текущие веса признаков:  [-1.89137865 -0.45684081 -0.75562742  0.69934564  1.77367256]\n",
      "Текущие веса признаков:  [-1.82706296 -0.38279151 -0.68478686  0.78652263  1.87038005]\n",
      "Текущие веса признаков:  [-1.91899614 -0.46720293 -0.77198805  0.71499161  1.81194842]\n",
      "Текущие веса признаков:  [-1.85480454 -0.39332571 -0.70130628  0.80189263  1.90824566]\n",
      "Текущие веса признаков:  [-1.94646296 -0.4774982  -0.78825874  0.73051644  1.84987522]\n",
      "Текущие веса признаков:  [-1.88235027 -0.40374537 -0.71768867  0.81719282  1.94581735]\n",
      "Текущие веса признаков:  [-1.97378596 -0.48772969 -0.80444345  0.74592316  1.88746292]\n",
      "Текущие веса признаков:  [-1.90970703 -0.41405371 -0.73393811  0.83242582  1.98310442]\n",
      "Текущие веса признаков:  [-2.00097001 -0.49789871 -0.82054432  0.7612161   1.92472233]\n",
      "Текущие веса признаков:  [-1.93688282 -0.42425543 -0.75006005  0.84759231  2.02011379]\n",
      "Текущие веса признаков:  [-2.02801823 -0.50800517 -0.83656198  0.77640053  1.96166462]\n",
      "Текущие веса признаков:  [-1.96388625 -0.43435618 -0.7660608   0.86269147  2.05685041]\n",
      "Текущие веса признаков:  [-2.05493233 -0.51804788 -0.85249587  0.79148219  1.99830089]\n",
      "Текущие веса признаков:  [-1.99072609 -0.44436213 -0.78194706  0.8777214   2.09331756]\n",
      "Текущие веса признаков:  [-2.08171298 -0.52802502 -0.86834463  0.80646695  2.03464181]\n",
      "Текущие веса признаков:  [-2.01741083 -0.45427957 -0.79772551  0.89267955  2.12951737]\n",
      "Текущие веса признаков:  [-2.10836018 -0.53793439 -0.88410647  0.82136048  2.07069725]\n",
      "Текущие веса признаков:  [-2.04394839 -0.46411449 -0.81340246  0.90756318  2.16545122]\n",
      "Текущие веса признаков:  [-2.13487365 -0.54777384 -0.89977951  0.83616798  2.10647613]\n",
      "Текущие веса признаков:  [-2.07034582 -0.47387228 -0.82898353  0.92236968  2.20112016]\n",
      "Текущие веса признаков:  [-2.16125312 -0.55754149 -0.91536207  0.85089395  2.14198628]\n",
      "Текущие веса признаков:  [-2.09660913 -0.48355755 -0.84447348  0.93709693  2.23652531]\n",
      "Текущие веса признаков:  [-2.18749865 -0.56723598 -0.93085294  0.86554206  2.17723434]\n",
      "Текущие веса признаков:  [-2.12274327 -0.49317393 -0.85987603  0.95174347  2.27166817]\n",
      "Текущие веса признаков:  [-2.21361082 -0.57685663 -0.94625151  0.88011514  2.21222589]\n",
      "Текущие веса признаков:  [-2.14875208 -0.50272407 -0.87519392  0.9663087   2.30655081]\n",
      "Текущие веса признаков:  [-2.23959084 -0.58640346 -0.96155788  0.89461515  2.24696549]\n",
      "Текущие веса признаков:  [-2.17463841 -0.51220969 -0.8904289   0.98079289  2.34117605]\n",
      "Текущие веса признаков:  [-2.26544062 -0.59587723 -0.97677288  0.9090433   2.28145688]\n",
      "Текущие веса признаков:  [-2.20040429 -0.52163161 -0.9055819   0.99519713  2.37554748]\n",
      "Текущие веса признаков:  [-2.29116275 -0.60527935 -0.99189798  0.92340015  2.31570316]\n",
      "Обучение модели закончено\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "iterations = 100\n",
    "impulse = 0.98 \n",
    "epsilon = 0.00001\n",
    "\n",
    "# создадим регрессор отдельно под RMSprop\n",
    "regressor_RMSprop = LogReg(X, Y)\n",
    "\n",
    "# обучим регрессор методом RMSprop\n",
    "regressor_RMSprop.fit_rmsprop(lr, iterations, impulse, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cda06c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим качество предсказаний, возьмем порог 0.5\n",
    "y_pred = regressor_RMSprop.predict(X, 0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cffa23ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.89\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', sum(y_pred == Y) / Y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0206ec7",
   "metadata": {},
   "source": [
    "Точность предсказаний почему-то ещё снизилась (c 0.92 у Нестеров Моментум до 0.89 у RMSProp), причем ошибки в основном в предсказании класса virginica (\"1\" в бинарной классификации).\n",
    "\n",
    "Самое высокое качество предсказаний получилось у модели обучения логистической регрессии стандартным способом (accuracy = 0.96)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
